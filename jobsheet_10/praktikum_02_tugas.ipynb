{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPt4gAZU9RVzfgwgjYyA/4t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhayuIntan/Machine_Learning/blob/main/jobsheet_10/praktikum_02_tugas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Praktikum 2**\n",
        "## Generator Teks dengan RNN"
      ],
      "metadata": {
        "id": "WBPFXj6Vmst0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setup**"
      ],
      "metadata": {
        "id": "8aU9cURAnYPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import TensorFlow**"
      ],
      "metadata": {
        "id": "t5lQFyYMna_c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JfN24VQtml7y"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Download Dataset Shakespeare**"
      ],
      "metadata": {
        "id": "Q-oftYZcnsM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ-C2IlanuWS",
        "outputId": "c28b6fe0-121d-480c-b4a7-15022472a1d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Data**"
      ],
      "metadata": {
        "id": "gIU1MAgZn2z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1C2eRIfn7k8",
        "outputId": "0d87b06d-fd49-49fb-db3b-bbca0feafb7d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0YrvAQIn_KV",
        "outputId": "293b5463-e03c-4c1e-903c-87cb923ddf2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSQzm8GaoKk0",
        "outputId": "db3629d6-b284-4473-edaa-c5d409ab45c1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Olah Teks**"
      ],
      "metadata": {
        "id": "rKuwSoP_oOw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Vectorize Teks**\n",
        "tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ],
      "metadata": {
        "id": "Z4xdYSymoWZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QayNsnq1oRfy",
        "outputId": "2e3d3b94-eb4c-4720-d9c3-e4fb5bb5fb56"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sekarang buat tf.keras.layers.StringLookup layer:"
      ],
      "metadata": {
        "id": "fkR30uwDo6f_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab),\n",
        "    mask_token=None\n",
        ")"
      ],
      "metadata": {
        "id": "LRs_xh50o8ov"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "perintah diatas mengconvert token menjadi id"
      ],
      "metadata": {
        "id": "8GVFmPb_pLRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orljZN25pMP-",
        "outputId": "b113ee6c-f225-4edc-ca05-8f1dc7c0e729"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "Ia863Av2pxig"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter tf.RaggedTensor:"
      ],
      "metadata": {
        "id": "qItqywerp2W0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lneOuk7Zp3B6",
        "outputId": "a9f6d2fc-2f3b-4659-a847-a27699910478"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gunakan tf.strings.reduce_join untuk menggabungkan kembali karakter menjadi string."
      ],
      "metadata": {
        "id": "B6eH9KT9qADJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFFiNCtMqCzM",
        "outputId": "c5f67001-8141-42e6-853a-2cc6e651cc68"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "xVNZcIexqIoN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Prediksi**"
      ],
      "metadata": {
        "id": "qdURA4a3qUUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diberikan sebuah karakter, atau serangkaian karakter, karakter apa yang paling mungkin berikutnya? Ini adalah tugas yang harus Anda latih agar model dapat melakukannya. Masukan ke model akan berupa urutan karakter, dan Anda melatih model untuk memprediksi keluaran berupa karakter berikut pada setiap langkah waktu. Karena RNN mempertahankan keadaan internal yang bergantung pada elemen yang terlihat sebelumnya, dan mengingat semua karakter dihitung hingga saat ini."
      ],
      "metadata": {
        "id": "s0T072lJqWRk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Membuat Trianing Set dan Target**\n",
        "Gunakan fungsi tf.data.Dataset.from_tensor_slices untuk mengonversi vektor teks menjadi aliran indeks karakter."
      ],
      "metadata": {
        "id": "Tx9Qx8QDqiKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmoPGMOWq5es",
        "outputId": "e91ec3f9-b0fb-41d8-eac5-f228b9c4482d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "KVQ6IVItq97G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPXZf0DJrDbr",
        "outputId": "bb0c6d18-c188-4310-8bae-4eb46ccd1419"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100"
      ],
      "metadata": {
        "id": "n1PB-qEbrJJY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metode batch memungkinkan Anda dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ],
      "metadata": {
        "id": "RDpKiJHMrRo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "    print(chars_from_ids(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhK7_AmxrWBZ",
        "outputId": "d0277dd3-6961-438d-ed6e-f6d24d450e63"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ],
      "metadata": {
        "id": "wv-ZhQRgrlVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuxBJvw2rgzc",
        "outputId": "1f720e28-bff7-468c-9609-54816e447944"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "u7aD0dXtr3ex"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXtPf-zlr_dd",
        "outputId": "641d62c3-5881-4744-81d8-017fb50cab67"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "vxLCgdTKsBDs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIU6i5PHsKPe",
        "outputId": "e9c015eb-1c06-4a89-c5cf-73b2d2c188a1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Membuat Batch Training**"
      ],
      "metadata": {
        "id": "zvoeQJrXsQSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6Igs8lSsTZ-",
        "outputId": "0d1e1e0b-4a98-4c07-8c8e-2f9655e065f4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Buat Model**"
      ],
      "metadata": {
        "id": "wRMRMuh0sawE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model memiliki 3 lapisan neural network :\n",
        "\n",
        "\n",
        "*   tf.keras.layers.Embedding: Lapisan masukan. Tabel pencarian yang dapat dilatih yang akan memetakan setiap karakter-ID ke vektor dengan dimensi embedding_dim;\n",
        "*   tf.keras.layers.GRU: lapisan RNN dengan ukuran unit=rnn_units (Anda juga dapat menggunakan lapisan LSTM di sini.)\n",
        "* tf.keras.layers.Dense: Lapisan keluaran, dengan keluaran vocab_size. Ini menghasilkan satu logit untuk setiap karakter dalam kosakata. Ini adalah log kemungkinan setiap karakter menurut model.\n",
        "\n"
      ],
      "metadata": {
        "id": "HjOZv3d7s1sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "kPqWk9i8s-vt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "ZddkSzywsqGF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "92j1p-YxtE5F"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Uji Model**"
      ],
      "metadata": {
        "id": "bZZVIcDwtXKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpldnQvQtZE6",
        "outputId": "f5220ff7-083b-4db6-b311-81c20346c267"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TALrNcLSthA_",
        "outputId": "d6df7f49-2a99-44ea-b11f-4849cc470eb3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "7IEZD79otxHN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada setiap langkah waktu, prediksi indeks karakter berikutnya:"
      ],
      "metadata": {
        "id": "0YDaI_LKt89Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLNvpWQbt-aj",
        "outputId": "1af198e6-a2ce-4709-f42d-164cb4a1a748"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([28,  3, 63, 33, 39, 50, 27, 51, 38, 21, 45, 30, 55,  3, 54, 58,  9,\n",
              "       64, 46, 42, 34, 20, 28, 16, 36, 43,  6, 21, 47, 46, 40, 17,  2, 53,\n",
              "       26,  4, 49, 59,  7, 41,  6, 32, 45,  5, 34, 30, 12, 37, 46, 20,  6,\n",
              "       52, 48,  3, 13, 40, 34,  7, 24, 29,  5, 43,  4, 40,  1, 47, 44, 20,\n",
              "       12,  5, 24,  3, 46, 36, 47, 55, 17, 17, 39, 46, 28, 47,  5, 36,  8,\n",
              "       29, 58, 23, 14, 28, 11, 38, 61, 10, 60, 24, 13, 12,  8, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dekode kode berikut untuk melihat teks yang diprediksi oleh model tidak terlatih ini:"
      ],
      "metadata": {
        "id": "T0le5QieuEFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-xQzkw7uEw0",
        "outputId": "ed58c644-dacc-4c96-fc21-07e5bb738a95"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'your wit restored!\\nO, that once more you knew but what you are!\\nThese fifteen years you have been in'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"O!xTZkNlYHfQp!os.ygcUGOCWd'HhgaD nM$jt,b'Sf&UQ;XgG'mi!?aU,KP&d$a\\nheG;&K!gWhpDDZgOh&W-PsJAO:Yv3uK?;-y\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train Model**"
      ],
      "metadata": {
        "id": "I64QsLSAuU_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tambahkan optimizer dan fungsi loss**"
      ],
      "metadata": {
        "id": "KIQlJrFSucEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "f1jb2VBwufva"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B-ozkd4ulLm",
        "outputId": "4802f549-d6d4-46ec-9e15-bd58a5b55d40"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1901174, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Periksa apakah eksponensial dari loss rata-rata kira-kira sama dengan ukuran kosakata. Loss yang jauh lebih tinggi berarti model tersebut yakin akan jawaban yang salah, dan memiliki inisialisasi yang buruk:"
      ],
      "metadata": {
        "id": "4h1O3OVwuv2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClU2tBs7u5E_",
        "outputId": "0b075d13-99af-44bf-97cb-f6732accd782"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.03054"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasikan prosedur pelatihan menggunakan metode tf.keras.Model.compile. Gunakan tf.keras.optimizers.Adam dengan argumen default dan fungsi loss."
      ],
      "metadata": {
        "id": "1ZBYwsVYvAcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "bGiDNHspvBFq"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Konfigurasi Checkpoints**"
      ],
      "metadata": {
        "id": "AkNZmFxYvC0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gunakan tf.keras.callbacks.ModelCheckpoint untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ],
      "metadata": {
        "id": "1zxf9Z6DvLux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "CfD95zy8vJce"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lakukan Proses Training**"
      ],
      "metadata": {
        "id": "ls1VotskvPuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20"
      ],
      "metadata": {
        "id": "j0ae6OcHvW7-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZwD9JQ1vnCL",
        "outputId": "8aba21a7-bfc3-475d-961a-441360526a4c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 14s 55ms/step - loss: 2.7063\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.9859\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.7156\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 12s 55ms/step - loss: 1.5570\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 1.4577\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 15s 62ms/step - loss: 1.3898\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 15s 62ms/step - loss: 1.3368\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 14s 60ms/step - loss: 1.2918\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 1.2520\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.2127\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 14s 60ms/step - loss: 1.1739\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 13s 59ms/step - loss: 1.1349\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 1.0925\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 1.0483\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.0012\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 0.9520\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.9022\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 0.8510\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 0.7982\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 0.7501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat prediksi satu langkah:"
      ],
      "metadata": {
        "id": "1VR6EAkUwPen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "zGVB_nrCwS4y"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "7H4DF_JZwWiH"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HO2pHd2wjEf",
        "outputId": "78f74b16-c6f7-4e01-b573-777d8714d5a8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Even art thou years? his son shot arms,\n",
            "If thy old consent all my needing, have embiding\n",
            "Romeo, what dont their lots this hard, and\n",
            "to differeign might frank, and humour'd thoughts, slaughters,\n",
            "His wealth of Pompery.\n",
            "\n",
            "MARCIUS:\n",
            "Do remain, as well as herself, beseech you any\n",
            "That we 'njuct me force. But what saundst thou not?\n",
            "\n",
            "LUCENTIO:\n",
            "Didst perife\n",
            "With resemfting in that sin\n",
            "To move our deputy.\n",
            "\n",
            "VINCENTIO:\n",
            "What is the model whereof, if it do not\n",
            "Unsturbuh thee this blushes and bran himself,\n",
            "Stulls for Edward: but thou sett'st manifest?\n",
            "\n",
            "BATTONSOP:\n",
            "I ne'er a sword, for how Juliet.\n",
            "\n",
            "Clown:\n",
            "He seems to make this late: little love,\n",
            "Sweat love it. Heaven meet thee protect him I will put demand.\n",
            "3 KING HENRY VI\n",
            "\n",
            "KING HENRY VI:\n",
            "Hadst thou pluck my fame and very suncher's demand?\n",
            "Yourself, as thou diest true; thou'rt in rest,\n",
            "And sigh'd false Edmiode, steal it, and came\n",
            "That e'er I come, in't speaking, wast whoreshapts and mode?\n",
            "Hadst thou not shed the good gods behind you; York and England's \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.9137649536132812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSwnbo2-wn24",
        "outputId": "3519f446-a9ad-4381-d129-5f76dcd6865b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "These secessions women once great Henry, royal grand;\n",
            "And thou nog at the point.\n",
            "\n",
            "GLOUCESTER:\n",
            "Love with him to't.\n",
            "\n",
            "PRINCE:\n",
            "We sea, if it do, I am false for: but do not slow,\n",
            "I'll voice us and now by himself.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I'll pray thee, As the truth I have to understand myself:\n",
            "A servant granted and run bastards, and my revenue intitle,\n",
            "with tears was't therein and sparl to gift me Henry.\n",
            "\n",
            "CLIFFORD:\n",
            "And here I leave, I would say, knock advices\n",
            "of noble pursuing; and I choose hang her;\n",
            "And thou the lie-giver penutoo, he\n",
            "makes fears so well, To-morrow to your meetinguars!\n",
            "\n",
            "YORK:\n",
            "I would be subjects to a keeper. A beggar studied\n",
            "I have at one and a penitent poor.\n",
            "\n",
            "Page:\n",
            "Sirrah, hold thy unharphus-and an old man's milk at midning.\n",
            "\n",
            "SAMPSON:\n",
            "Fear none, and, bear, her cunning.\n",
            "\n",
            "MARCIUS:\n",
            "Then, tell me,'t, a stirrior, master, leave the\n",
            "spept wax of justice,' and that willing to\n",
            "considered, then, adieu;\n",
            "Go; tell us rich, then I pretition\n",
            "These diversion will show you mercy;\n",
            "For he hath kil \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.7099664211273193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ekspor Model Generator**"
      ],
      "metadata": {
        "id": "BnDWE1bXwrHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-vYQtIEwuDl",
        "outputId": "6ae001a0-d069-465b-d6ff-21db7659c793"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7c047ef4bb20>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKIKW7CPwycf",
        "outputId": "3d00f20a-a940-4daa-832f-37c9837bb37e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Katharina,\n",
            "An you but fair, by witness, shall at you much disglades;\n",
            "They were these nature's frown\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tugas**"
      ],
      "metadata": {
        "id": "meD4H2NS27U8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "    inputs, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self(inputs, training=True)\n",
        "      loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ],
      "metadata": {
        "id": "jHToHiZ229rA"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units\n",
        ")"
      ],
      "metadata": {
        "id": "G3_Zbb-l30gz"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        ")"
      ],
      "metadata": {
        "id": "-Gcs6LLv3_gU"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIJP9THy4Glh",
        "outputId": "30cffd71-0bb4-49ef-93b2-df98b3683615"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172/172 [==============================] - 14s 61ms/step - loss: 2.6806\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c045bcf49a0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "        logs = model.train_step([inp, target])\n",
        "        mean.update_state(logs['loss'])\n",
        "\n",
        "        if batch_n % 50 == 0:\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "            print(template)\n",
        "\n",
        "    # saving (checkpoint) the model every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7sBMhJt4P_4",
        "outputId": "73d2bd4f-1052-40bc-e985-a6b14203fae9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1823\n",
            "Epoch 1 Batch 50 Loss 2.0557\n",
            "Epoch 1 Batch 100 Loss 1.9586\n",
            "Epoch 1 Batch 150 Loss 1.8436\n",
            "\n",
            "Epoch 1 Loss: 1.9692\n",
            "Time taken for 1 epoch 13.16 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.8022\n",
            "Epoch 2 Batch 50 Loss 1.7794\n",
            "Epoch 2 Batch 100 Loss 1.6933\n",
            "Epoch 2 Batch 150 Loss 1.6201\n",
            "\n",
            "Epoch 2 Loss: 1.6981\n",
            "Time taken for 1 epoch 11.53 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.5602\n",
            "Epoch 3 Batch 50 Loss 1.5981\n",
            "Epoch 3 Batch 100 Loss 1.4975\n",
            "Epoch 3 Batch 150 Loss 1.5190\n",
            "\n",
            "Epoch 3 Loss: 1.5435\n",
            "Time taken for 1 epoch 11.28 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4703\n",
            "Epoch 4 Batch 50 Loss 1.4452\n",
            "Epoch 4 Batch 100 Loss 1.4101\n",
            "Epoch 4 Batch 150 Loss 1.4484\n",
            "\n",
            "Epoch 4 Loss: 1.4468\n",
            "Time taken for 1 epoch 11.22 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.3864\n",
            "Epoch 5 Batch 50 Loss 1.4097\n",
            "Epoch 5 Batch 100 Loss 1.3711\n",
            "Epoch 5 Batch 150 Loss 1.3739\n",
            "\n",
            "Epoch 5 Loss: 1.3811\n",
            "Time taken for 1 epoch 11.28 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3260\n",
            "Epoch 6 Batch 50 Loss 1.3258\n",
            "Epoch 6 Batch 100 Loss 1.3302\n",
            "Epoch 6 Batch 150 Loss 1.3362\n",
            "\n",
            "Epoch 6 Loss: 1.3286\n",
            "Time taken for 1 epoch 11.13 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2784\n",
            "Epoch 7 Batch 50 Loss 1.2646\n",
            "Epoch 7 Batch 100 Loss 1.2701\n",
            "Epoch 7 Batch 150 Loss 1.3080\n",
            "\n",
            "Epoch 7 Loss: 1.2845\n",
            "Time taken for 1 epoch 11.20 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2335\n",
            "Epoch 8 Batch 50 Loss 1.2147\n",
            "Epoch 8 Batch 100 Loss 1.2405\n",
            "Epoch 8 Batch 150 Loss 1.2814\n",
            "\n",
            "Epoch 8 Loss: 1.2439\n",
            "Time taken for 1 epoch 11.30 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.1673\n",
            "Epoch 9 Batch 50 Loss 1.1948\n",
            "Epoch 9 Batch 100 Loss 1.1896\n",
            "Epoch 9 Batch 150 Loss 1.2476\n",
            "\n",
            "Epoch 9 Loss: 1.2042\n",
            "Time taken for 1 epoch 11.29 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1368\n",
            "Epoch 10 Batch 50 Loss 1.1587\n",
            "Epoch 10 Batch 100 Loss 1.1602\n",
            "Epoch 10 Batch 150 Loss 1.1691\n",
            "\n",
            "Epoch 10 Loss: 1.1653\n",
            "Time taken for 1 epoch 11.61 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SOAL**\n",
        "Jalankan kode diatas dan sebutkan perbedaanya dengan praktikum 2?"
      ],
      "metadata": {
        "id": "4k3j6ofT4XcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **JAWABAN**"
      ],
      "metadata": {
        "id": "i_nNZCcC4f9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada praktikum, proses yang dilakukan lebih sederhana yaitu dengan otomisasi menggunakan fungsi 'model.fit()', sedangkan pada tugas digunakan custom training loop sehingga kita dapat mengatur langkah-langkah pelatihan, seperti perhitungan gradien, optimasi, dan pelaporan. Pada tugas digunakan metode 'train_step' yang dapat menghitung gradien loss terhadap parameter model untuk digunakan dalam mengupdate parameter model. Selain itu, pada tugas digunakan objek tf.metrics.Mean() untuk memantau rata-rata loss selama pelatihan. Kemudian, pada setiap batch, rata-rata loss diperbarui dengan memanggil mean.update_state(logs['loss']) sehingga memungkinkan kita untuk melacak perubahan loss secara dinamis selama pelatihan. Secara umum, pada kode tugas, kita memiliki lebih banyak kontrol untuk memantau serta mengelola proses pelatihan yang sesuai."
      ],
      "metadata": {
        "id": "mVuHPF4h4ip8"
      }
    }
  ]
}